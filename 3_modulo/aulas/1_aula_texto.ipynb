{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install -U spacy\n",
    "%python -m spacy download en_core_web_sm\n",
    "%pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import spacy.cli\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/dorival/.local/lib/python3.9/site-packages (from en-core-web-lg==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (61.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.22.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.22.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/dorival/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dorival/.local/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.1.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/dorival/.local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dorival/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/dorival/.local/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dorival/.local/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.8)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dorival/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.cli.download('en_core_web_lg')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Texto original\n",
      "The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model .\n",
      "--------------\n",
      "Remoção de stopwords e pontuação\n",
      "[GeoSolutions, technology, leverage, Benefon, GPS, solutions, providing, Location, Based, Search, Technology, Communities, Platform, location, relevant, multimedia, content, new, powerful, commercial, model]\n",
      "--------------\n",
      "Lemmatization\n",
      "['geosolutions', 'technology', 'leverage', 'benefon', 'gps', 'solution', 'provide', 'location', 'based', 'search', 'technology', 'communities', 'platform', 'location', 'relevant', 'multimedia', 'content', 'new', 'powerful', 'commercial', 'model']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "texto = df.Sentence[0]\n",
    "\n",
    "print('--------------')\n",
    "print('Texto original')\n",
    "print(texto)\n",
    "\n",
    "doc = nlp(texto)\n",
    "# Cada token que estiver dentro do documento você mantem caso não seja uma stopword ou pontuação(punch)  \n",
    "tokens_filtrado = [token for token in doc if ((not token.is_stop) & (not token.is_punct))]\n",
    "\n",
    "print('--------------')\n",
    "print('Remoção de stopwords e pontuação')\n",
    "print(tokens_filtrado)\n",
    "\n",
    "lemmas = [token.lemma_.lower().strip() for token in tokens_filtrado]\n",
    "\n",
    "print('--------------')\n",
    "print('Lemmatization')\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a Construa as funções e a pipeline, separe os dados em treino e teste, execute a pipeline para classificar em positivo, negativo e neutro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma classe para gerenciar X e y\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Esta funcao remove espacos em branco no inicio e\n",
    "# no fim do texto e converte todo o texto em letras\n",
    "# minusculas\n",
    "def clean_text(texto):     \n",
    "    return texto.strip().lower()\n",
    "\n",
    "# Esta funcao remove todas as stopwords e pontuacoes\n",
    "def tokenizer(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = [token for token in doc if ((not token.is_stop) & (not token.is_punct))]\n",
    "    tokens = [token.lemma_.lower().strip() for token in tokens]\n",
    "    return tokens \n",
    "#criamos um objeto CountVectorizer para vetorizar cada texto\n",
    "vectorizer = CountVectorizer(tokenizer = tokenizer, ngram_range=(1,1))\n",
    "\n",
    "#criamos um modelo SVM\n",
    "classifier = SVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separando em X e y\n",
    "X = df.Sentence\n",
    "y = df.Sentiment\n",
    "\n",
    "# Separando em teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construindo uma pipeline\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.b Quais foram os valores de acurácia, precisão e sensitividade deste modelo? (3.0 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681\n",
      "0.596\n",
      "0.526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(round(accuracy_score(y_test, y_pred), 3))\n",
    "print(round(precision_score(y_test, y_pred, average='macro'), 3))\n",
    "print(round(recall_score(y_test, y_pred, average='macro'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 Use o seu modelo para classificar os seguintes textos extraídos do site Financial Times. Faça uma tabela com o valor esperado e o valor obtido, e responda: houve divergência entre o esperado e o obtido? O que poderia ser feito para corrigir? (1.0 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central banks’ rate rises, geopolitical risk a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China opens up bond market in bid to woo forei...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HM Revenue &amp; Customs says residents had £850bn...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan’s horrifying crop of data falsification ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite internal problems, the group continues...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  Central banks’ rate rises, geopolitical risk a...  negative\n",
       "1  China opens up bond market in bid to woo forei...   neutral\n",
       "2  HM Revenue & Customs says residents had £850bn...  negative\n",
       "3  Japan’s horrifying crop of data falsification ...  negative\n",
       "4  Despite internal problems, the group continues...   neutral"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_dict = {\n",
    "                  \"Sentence\": [\"Central banks’ rate rises, geopolitical risk and slowing growth trigger investors’ stampede for safety.\",\n",
    "                          \"China opens up bond market in bid to woo foreign investors.\",\n",
    "                          \"HM Revenue & Customs says residents had £850bn in accounts overseas but it does not estimate if tax paid on this.\",\n",
    "                          \"Japan’s horrifying crop of data falsification is also encouraging. The scandals have emerged from a distinct new phase in the evolution of the country’s shareholder capitalism.\",\n",
    "                          \"Despite internal problems, the group continues to exert a tight grip on the US’s gun control debate.\"],\n",
    "                  \"Sentiment\": [\"negative\", \"neutral\", \"negative\", \"negative\", \"neutral\"]        \n",
    "                          }\n",
    "                          \n",
    "new_data = pd.DataFrame(new_data_dict)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = pipe.predict(new_data['Sentence'])\n",
    "print(round(accuracy_score(new_data['Sentiment'], y_pred), 3))\n",
    "print(round(precision_score(new_data['Sentiment'], y_pred, average='macro'), 3))\n",
    "print(round(recall_score(new_data['Sentiment'], y_pred, average='macro'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Original Sentiment</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "      <th>Divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central banks’ rate rises, geopolitical risk a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China opens up bond market in bid to woo forei...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HM Revenue &amp; Customs says residents had £850bn...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan’s horrifying crop of data falsification ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite internal problems, the group continues...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Original Sentiment  \\\n",
       "0  Central banks’ rate rises, geopolitical risk a...           negative   \n",
       "1  China opens up bond market in bid to woo forei...            neutral   \n",
       "2  HM Revenue & Customs says residents had £850bn...           negative   \n",
       "3  Japan’s horrifying crop of data falsification ...           negative   \n",
       "4  Despite internal problems, the group continues...            neutral   \n",
       "\n",
       "  Predicted Sentiment  Divergence  \n",
       "0            positive        True  \n",
       "1             neutral       False  \n",
       "2             neutral        True  \n",
       "3             neutral        True  \n",
       "4             neutral       False  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = new_data_dict['Sentence']\n",
    "sentiments_or = new_data_dict['Sentiment']\n",
    "sentiments_pred = y_pred2\n",
    "\n",
    "values_dict = {\"Sentence\": sentences, \"Original Sentiment\": sentiments_or, \"Predicted Sentiment\": sentiments_pred}\n",
    "\n",
    "values_df = pd.DataFrame(values_dict)\n",
    "\n",
    "values_df['Divergence'] = values_df[\"Predicted Sentiment\"] != values_df[\"Original Sentiment\"]\n",
    "\n",
    "values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     3\n",
       "False    2\n",
       "Name: Divergence, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df['Divergence'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Faça uma análise exploratória, onde identifique as três empresas mais citadas e quantifique os níveis de positividade, negatividade e neutralidade dos textos sobre estas empresas. (3.0 pontos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Extraia de todos os textos as entidades, há quantas entidades? (0.6 pontos) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14467\n"
     ]
    }
   ],
   "source": [
    "entities = 0\n",
    "for row in range(len(df['Sentence'])):\n",
    "  doc = nlp(df['Sentence'][row])\n",
    "  for ent in doc.ents:\n",
    "    entities += 1\n",
    "\n",
    "           \n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Quantas entidades são empresas? (0.6 pontos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GeoSolutions</td>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Location Based Search Technology</td>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ESI</td>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>BK</td>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SPY</td>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                            entity  \\\n",
       "0               0                      GeoSolutions   \n",
       "1               0  Location Based Search Technology   \n",
       "2               1                               ESI   \n",
       "3               1                                BK   \n",
       "4               5                               SPY   \n",
       "\n",
       "                                           sentiment  \n",
       "0  The GeoSolutions technology will leverage Bene...  \n",
       "1  The GeoSolutions technology will leverage Bene...  \n",
       "2  $ESI on lows, down $1.50 to $2.50 BK a real po...  \n",
       "3  $ESI on lows, down $1.50 to $2.50 BK a real po...  \n",
       "4    $SPY wouldn't be surprised to see a green close  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs = {'original_index': [], 'entity': [], 'sentiment': []}\n",
    "for row in range(len(df['Sentence'])):\n",
    "  doc = nlp(df['Sentence'][row])\n",
    "  for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "      orgs['original_index'].append(row)\n",
    "      orgs['entity'].append(ent.text)\n",
    "      orgs['sentiment'].append(df['Sentence'][row])\n",
    "\n",
    "ents = pd.DataFrame(orgs)\n",
    "ents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " c. Quais são as três empresas mais citadas? (0.6 pontos) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Faça uma tabela onde demonstre as três empresas mais citadas e o total de textos positivos, negativos e neutros de cada uma. (1.2 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '1']\n"
     ]
    }
   ],
   "source": [
    "#pegar uma lista com palavras que se repetem e deixar só a original\n",
    "\n",
    "lista = ['1', '2', '3', '1']\n",
    "lista = list(set(lista))\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu ORG\n",
      "mais barata PERSON\n",
      "Brasil PERSON\n",
      "9.99 MONEY\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp('Eu tenho usado o serviço de armazenamento na nuvem da Google, é a opção mais barata no Brasil, pago somente R$ 9.99 por mês.')\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
